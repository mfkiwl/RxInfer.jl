<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>System Identification Problem · RxInfer.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://biaslab.github.io/RxInfer.jl/examples/Identification Problem/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../assets/header.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="RxInfer.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="RxInfer.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">RxInfer.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">User guide</span><ul><li><a class="tocitem" href="../../manuals/getting-started/">Getting started</a></li><li><a class="tocitem" href="../../manuals/model-specification/">Model specification</a></li><li><a class="tocitem" href="../../manuals/constraints-specification/">Constraints specification</a></li><li><a class="tocitem" href="../../manuals/meta-specification/">Meta specification</a></li><li><input class="collapse-toggle" id="menuitem-2-5" type="checkbox"/><label class="tocitem" for="menuitem-2-5"><span class="docs-label">Inference specification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../manuals/inference/overview/">Overview</a></li><li><a class="tocitem" href="../../manuals/inference/inference/">Static dataset</a></li><li><a class="tocitem" href="../../manuals/inference/rxinference/">Real-time dataset / reactive inference</a></li><li><a class="tocitem" href="../../manuals/inference/postprocess/">Inference results postprocessing</a></li><li><a class="tocitem" href="../../manuals/inference/manual/">Manual inference specification</a></li></ul></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../library/functional-forms/">Built-in functional form constraints</a></li><li><a class="tocitem" href="../../library/model-specification/">Model specification</a></li><li><a class="tocitem" href="../../library/bethe-free-energy/">Bethe Free Energy</a></li><li><a class="tocitem" href="../../library/exported-methods/">Exported methods</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../Coin Toss Model/">Coin toss model (Beta-Bernoulli)</a></li><li><a class="tocitem" href="../Linear Regression/">Bayesian Linear Regression</a></li><li><a class="tocitem" href="../Active Inference Mountain car/">Active Inference Mountain car</a></li><li><a class="tocitem" href="../Assessing People Skills/">Assessing People’s Skills</a></li><li><a class="tocitem" href="../Gaussian Linear Dynamical System/">Gaussian Linear Dynamical System</a></li><li><a class="tocitem" href="../Hidden Markov Model/">Ensemble Learning of a Hidden Markov Model</a></li><li><a class="tocitem" href="../Autoregressive Model/">Autoregressive Model</a></li><li><a class="tocitem" href="../Hierarchical Gaussian Filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../Bayesian ARMA/">Bayesian ARMA model</a></li><li><a class="tocitem" href="../Infinite Data Stream/">Infinite Data Stream</a></li><li class="is-active"><a class="tocitem" href>System Identification Problem</a><ul class="internal"><li><a class="tocitem" href="#Two-merged-signals"><span>Two merged signals</span></a></li></ul></li><li><a class="tocitem" href="../Gaussian Mixture Univariate/">Univariate Gaussian Mixture Model</a></li><li><a class="tocitem" href="../Gaussian Mixtures Multivariate/">Multivariate Gaussian Mixture Model</a></li><li><a class="tocitem" href="../Gamma Mixture/">Gamma Mixture Model</a></li><li><a class="tocitem" href="../Universal Mixtures/">Universal Mixtures</a></li><li><a class="tocitem" href="../Global Parameter Optimisation/">Global Parameter Optimisation</a></li><li><a class="tocitem" href="../Invertible Neural Network Tutorial/">Invertible neural networks: a tutorial</a></li><li><a class="tocitem" href="../Conjugate-Computational Variational Message Passing/">Conjugate-Computational Variational Message Passing (CVI)</a></li><li><a class="tocitem" href="../GPRegression by SSM/">Solve GP regression by SDE</a></li><li><a class="tocitem" href="../Nonlinear Noisy Pendulum/">Nonlinear Smoothing: Noisy Pendulum</a></li><li><a class="tocitem" href="../Nonlinear Rabbit Population/">Nonlinear Smoothing: Rabbit Population</a></li><li><a class="tocitem" href="../Nonlinear Virus Spread/">Nonlinear Virus Spread</a></li><li><a class="tocitem" href="../Nonlinear Sensor Fusion/">Nonlinear Sensor Fusion</a></li><li><a class="tocitem" href="../Kalman filter with LSTM network driven dynamic/">Kalman filter with LSTM network driven dynamic</a></li><li><a class="tocitem" href="../Handling Missing Data/">Handling Missing Data</a></li><li><a class="tocitem" href="../Custom nonlinear node/">Custom Nonlinear Node</a></li><li><a class="tocitem" href="../Probit Model (EP)/">Probit Model (EP)</a></li><li><a class="tocitem" href="../RTS vs BIFM Smoothing/">RTS vs BIFM Smoothing</a></li><li><a class="tocitem" href="../Advanced Tutorial/">Advanced Tutorial</a></li></ul></li><li><span class="tocitem">Contributing</span><ul><li><a class="tocitem" href="../../contributing/overview/">Overview</a></li><li><a class="tocitem" href="../../contributing/new-example/">Adding a new example</a></li><li><a class="tocitem" href="../../contributing/new-release/">Publishing a new release</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>System Identification Problem</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>System Identification Problem</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/biaslab/RxInfer.jl/blob/main/docs/src/examples/Identification Problem.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>This example has been auto-generated from the <a href="https://github.com/biaslab/RxInfer.jl/tree/main/examples"><code>examples/</code></a> folder at GitHub repository.</p><h1 id="examples-system-identification-problem"><a class="docs-heading-anchor" href="#examples-system-identification-problem">System Identification Problem</a><a id="examples-system-identification-problem-1"></a><a class="docs-heading-anchor-permalink" href="#examples-system-identification-problem" title="Permalink"></a></h1><pre><code class="language-julia hljs"># Activate local environment, see `Project.toml`
import Pkg; Pkg.activate(&quot;.&quot;); Pkg.instantiate();</code></pre><pre><code class="language-julia hljs">using RxInfer, Distributions, StableRNGs, Plots</code></pre><h2 id="Two-merged-signals"><a class="docs-heading-anchor" href="#Two-merged-signals">Two merged signals</a><a id="Two-merged-signals-1"></a><a class="docs-heading-anchor-permalink" href="#Two-merged-signals" title="Permalink"></a></h2><p>In this example we are going to attempt to run Bayesian inference and decouple two random-walk signals, which were combined into a single single through some deterministic function <code>f</code>. We do not have access to the real values of these signals, but only to their combination. First, we create the <code>generate_data</code> function that accepts <code>f</code> as an argument:</p><pre><code class="language-julia hljs">function generate_data(f, n; seed = 123, x_i_min = -20.0, w_i_min = 20.0, noise = 20.0, real_x_τ = 0.1, real_w_τ = 1.0)

    rng = StableRNG(seed)

    real_x = Vector{Float64}(undef, n)
    real_w = Vector{Float64}(undef, n)
    real_y = Vector{Float64}(undef, n)

    for i in 1:n
        real_x[i] = rand(rng, Normal(x_i_min, sqrt(1.0 / real_x_τ)))
        real_w[i] = rand(rng, Normal(w_i_min, sqrt(1.0 / real_w_τ)))
        real_y[i] = rand(rng, Normal(f(real_x[i], real_w[i]), sqrt(noise)))

        x_i_min = real_x[i]
        w_i_min = real_w[i]
    end
    
    return real_x, real_w, real_y
end</code></pre><pre><code class="nohighlight hljs">generate_data (generic function with 1 method)</code></pre><p>The function returns the real signals <code>real_x</code> and  <code>real_w</code> for later comparison (we are not going to use them during inference) and their combined version <code>real_y</code> (we are going to use it as our observations during the inference). We also assume that <code>real_y</code> is corrupted with some measurement noise.</p><h3 id="Combination-1:-y-x-w"><a class="docs-heading-anchor" href="#Combination-1:-y-x-w">Combination 1: y = x + w</a><a id="Combination-1:-y-x-w-1"></a><a class="docs-heading-anchor-permalink" href="#Combination-1:-y-x-w" title="Permalink"></a></h3><p>In our first example, we are going to use a simple addition (<code>+</code>) as the function <code>f</code>. In general, it is impossible to decouple the signals <code>x</code> and <code>w</code> without strong priors, but we can try and see how good an inference can be. The <code>+</code> operation on two random variables also has a special meaning in the probabilistic inference, namely the convolution of pdf&#39;s of the two random variables, and <code>RxInfer</code> treats it specially with many precomputed analytical rules, which may make the inference task easier. First, let us create a test dataset:</p><pre><code class="language-julia hljs">n = 250
real_x, real_w, real_y = generate_data(+, n);

pl = plot(title = &quot;Underlying signals&quot;)
pl = plot!(pl, real_x, label = &quot;x&quot;)
pl = plot!(pl, real_w, label = &quot;w&quot;)

pr = plot(title = &quot;Combined y = x + w&quot;)
pr = scatter!(pr, real_y, ms = 3, color = :red, label = &quot;y&quot;)

plot(pl, pr, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_4_1.png" alt/></p><p>To run inference, we need to create a probabilistic model: our beliefs about how our data could have been generated. For this we can use the <code>@model</code> macro from <code>RxInfer.jl</code>:</p><pre><code class="language-julia hljs">@model function identification_problem(f, n, m_x_0, τ_x_0, a_x, b_x, m_w_0, τ_w_0, a_w, b_w, a_y, b_y)
    
    x0 ~ Normal(mean = m_x_0, precision = τ_x_0)
    τ_x ~ Gamma(shape = a_x, rate = b_x)
    w0 ~ Normal(mean = m_w_0, precision = τ_w_0)
    τ_w ~ Gamma(shape = a_w, rate = b_w)
    τ_y ~ Gamma(shape = a_y, rate = b_y)
    
    x = randomvar(n)
    w = randomvar(n)
    s = randomvar(n)
    y = datavar(Float64, n)
    
    x_i_min = x0
    w_i_min = w0
    
    for i in 1:n
        x[i] ~ Normal(mean = x_i_min, precision = τ_x)
        w[i] ~ Normal(mean = w_i_min, precision = τ_w)
        s[i] ~ f(x[i], w[i])
        y[i] ~ Normal(mean = s[i], precision = τ_y)
        
        x_i_min = x[i]
        w_i_min = w[i]
    end
    
end</code></pre><p><code>RxInfer</code> runs Bayesian inference as a variational optimisation procedure between the real solution and its variational proxy <code>q</code>. In our model specification we assumed noise components to be unknown, thus, we need to enforce a structured mean-field assumption for the variational family of distributions <code>q</code>. This inevitably reduces the accuracy of the result, but makes the task easier and allows for fast and analytical message passing-based variational inference:</p><pre><code class="language-julia hljs">constraints = @constraints begin 
    q(x0, w0, x, w, τ_x, τ_w, τ_y, s) = q(x, x0, w, w0, s)q(τ_w)q(τ_x)q(τ_y)
end</code></pre><pre><code class="nohighlight hljs">Constraints:
  marginals form:
  messages form:
  factorisation:
    q(x0, w0, x, w, τ_x, τ_w, τ_y, s) = q(x, x0, w, w0, s)q(τ_w)q(τ_x)q(τ_y
)
Options:
  warn = true</code></pre><p>The next step is to assign priors, initialise needed messages and marginals and call the <code>inference</code> function:</p><pre><code class="language-julia hljs">m_x_0, τ_x_0 = -20.0, 1.0
m_w_0, τ_w_0 = 20.0, 1.0

# We set relatively strong priors for random walk noise components
# and sort of vague prior for the noise of the observations
a_x, b_x = 0.01, 0.01var(real_x)
a_w, b_w = 0.01, 0.01var(real_w)
a_y, b_y = 1.0, 1.0

# We set relatively strong priors for messages
xinit = map(r -&gt; NormalMeanPrecision(r, τ_x_0), reverse(range(-60, -20, length = n)))
winit = map(r -&gt; NormalMeanPrecision(r, τ_w_0), range(20, 60, length = n))

imessages = (x = xinit, w = winit)
imarginals = (τ_x = GammaShapeRate(a_x, b_x), τ_w = GammaShapeRate(a_w, b_w), τ_y = GammaShapeRate(a_y, b_y))

result = inference(
    model = identification_problem(+, n, m_x_0, τ_x_0, a_x, b_x, m_w_0, τ_w_0, a_w, b_w, a_y, b_y),
    data  = (y = real_y,), 
    options = (limit_stack_depth = 500, ), 
    constraints = constraints, 
    initmessages = imessages, 
    initmarginals = imarginals, 
    iterations = 50
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (w0, w, x0, s, τ_x, τ_w, τ_y, x)</code></pre><p>Let&#39;s examine our inference results:</p><pre><code class="language-julia hljs">τ_x_marginals = result.posteriors[:τ_x]
τ_w_marginals = result.posteriors[:τ_w]
τ_y_marginals = result.posteriors[:τ_y]

smarginals = result.posteriors[:s]
xmarginals = result.posteriors[:x]
wmarginals = result.posteriors[:w];</code></pre><pre><code class="language-julia hljs">px1 = plot(legend = :bottomleft, title = &quot;Estimated hidden signals&quot;)
px2 = plot(legend = :bottomright, title = &quot;Estimated combined signals&quot;)

px1 = plot!(px1, real_x, label = &quot;Real hidden X&quot;)
px1 = plot!(px1, mean.(xmarginals[end]), ribbon = var.(xmarginals[end]), label = &quot;Estimated X&quot;)

px1 = plot!(px1, real_w, label = &quot;Real hidden W&quot;)
px1 = plot!(px1, mean.(wmarginals[end]), ribbon = var.(wmarginals[end]), label = &quot;Estimated W&quot;)

px2 = scatter!(px2, real_y, label = &quot;Observations&quot;, ms = 2, alpha = 0.5, color = :red)
px2 = plot!(px2, mean.(smarginals[end]), ribbon = std.(smarginals[end]), label = &quot;Combined estimated signal&quot;, color = :green)

plot(px1, px2, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_9_1.png" alt/></p><p>The inference results are not so bad, even though <code>RxInfer</code> missed the correct values of the signals between <code>100</code> and <code>150</code>.</p><h3 id="Combination-2:-y-min(x,-w)"><a class="docs-heading-anchor" href="#Combination-2:-y-min(x,-w)">Combination 2: y = min(x, w)</a><a id="Combination-2:-y-min(x,-w)-1"></a><a class="docs-heading-anchor-permalink" href="#Combination-2:-y-min(x,-w)" title="Permalink"></a></h3><p>In this example we use a slightly more complex function, for which <code>RxInfer</code> does not have precomputed analytical message update rules. We are going to attempt to run Bayesian inference with <code>min</code> as a combination function. Note, however, that directly using <code>min</code> may cause problems for the built-in approximation methods as it has zero partial derviates with respect to all but one of the variables. We generate data with the <code>min</code> function directly however we model it with a somewhat smoothed version:</p><pre><code class="language-julia hljs"># Smoothed version of `min` without zero-ed derivatives
function smooth_min(x, y)    
    if x &lt; y
        return x + 1e-4 * y
    else
        return y + 1e-4 * x
    end
end</code></pre><pre><code class="nohighlight hljs">smooth_min (generic function with 1 method)</code></pre><p><code>RxInfer</code> supports arbitrary nonlinear functions, but it requires an explicit approximation method specification. That can be achieved with the built-in <code>@meta</code> macro:</p><pre><code class="language-julia hljs">min_meta = @meta begin 
    # In this example we are going to use a simple `Linearization` method
    smooth_min() -&gt; Linearization()
end</code></pre><pre><code class="nohighlight hljs">Meta specification:
  smooth_min() -&gt; Linearization()
Options:
  warn = true</code></pre><pre><code class="language-julia hljs">n = 200
min_real_x, min_real_w, min_real_y = generate_data(min, n, seed = 1, x_i_min = 0.0, w_i_min = 0.0, noise = 1.0, real_x_τ = 1.0, real_w_τ = 1.0);

pl = plot(title = &quot;Underlying signals&quot;)
pl = plot!(pl, min_real_x, label = &quot;x&quot;)
pl = plot!(pl, min_real_w, label = &quot;w&quot;)

pr = plot(title = &quot;Combined y = min(x, w)&quot;)
pr = scatter!(pr, min_real_y, ms = 3, color = :red, label = &quot;y&quot;)

plot(pl, pr, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_12_1.png" alt/></p><pre><code class="language-julia hljs">min_m_x_0, min_τ_x_0 = -1.0, 1.0
min_m_w_0, min_τ_w_0 = 1.0, 1.0

min_a_x, min_b_x = 1.0, 1.0
min_a_w, min_b_w = 1.0, 1.0
min_a_y, min_b_y = 1.0, 1.0

min_imessages = (x = NormalMeanPrecision(min_m_x_0, min_τ_x_0), w = NormalMeanPrecision(min_m_w_0, min_τ_w_0))
min_imarginals = (τ_x = GammaShapeRate(min_a_x, min_b_x), τ_w = GammaShapeRate(min_a_w, min_b_w), τ_y = GammaShapeRate(min_a_y, min_b_y))

min_result = inference(
    model = identification_problem(smooth_min, n, min_m_x_0, min_τ_x_0, min_a_x, min_b_x, min_m_w_0, min_τ_w_0, min_a_w, min_b_w, min_a_y, min_b_y),
    data  = (y = min_real_y,), 
    meta = min_meta,
    options = (limit_stack_depth = 500, ), 
    constraints = constraints, 
    initmessages = min_imessages, 
    initmarginals = min_imarginals, 
    iterations = 100
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (w0, w, x0, s, τ_x, τ_w, τ_y, x)</code></pre><pre><code class="language-julia hljs">min_τ_x_marginals = min_result.posteriors[:τ_x]
min_τ_w_marginals = min_result.posteriors[:τ_w]
min_τ_y_marginals = min_result.posteriors[:τ_y]

min_smarginals = min_result.posteriors[:s]
min_xmarginals = min_result.posteriors[:x]
min_wmarginals = min_result.posteriors[:w]

px1 = plot(legend = :bottomleft, title = &quot;Estimated hidden signals&quot;)
px2 = plot(legend = :bottomright, title = &quot;Estimated combined signals&quot;)

px1 = plot!(px1, min_real_x, label = &quot;Real hidden X&quot;)
px1 = plot!(px1, mean.(min_xmarginals[end]), ribbon = var.(min_xmarginals[end]), label = &quot;Estimated X&quot;)

px1 = plot!(px1, min_real_w, label = &quot;Real hidden W&quot;)
px1 = plot!(px1, mean.(min_wmarginals[end]), ribbon = var.(min_wmarginals[end]), label = &quot;Estimated W&quot;)

px2 = scatter!(px2, min_real_y, label = &quot;Observations&quot;, ms = 2, alpha = 0.5, color = :red)
px2 = plot!(px2, mean.(min_smarginals[end]), ribbon = std.(min_smarginals[end]), label = &quot;Combined estimated signal&quot;, color = :green)

plot(px1, px2, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_14_1.png" alt/></p><p>As we can see inference with the <code>min</code> function is significantly harder. Even though the combined signal has been inferred with high precision the underlying <code>x</code> and <code>w</code> signals are barely inferred. This may be expected, since the <code>min</code> function essentially destroy the information about one of the signals, thus, making it impossible to decouple two seemingly identical random walk signals. The only one inferred signal is the one which is lower and we have no inference information about the signal which is above. It might be possible to infer the states, however, with more informative priors and structural information about two different signals (e.g. if these are not random walks). </p><h3 id="Online-(filtering)-identification:-y-min(x,-w)"><a class="docs-heading-anchor" href="#Online-(filtering)-identification:-y-min(x,-w)">Online (filtering) identification: y = min(x, w)</a><a id="Online-(filtering)-identification:-y-min(x,-w)-1"></a><a class="docs-heading-anchor-permalink" href="#Online-(filtering)-identification:-y-min(x,-w)" title="Permalink"></a></h3><p>Another way to approach to this problem is to use online (filtering) inference procedure from <code>RxInfer</code>, but for that we also need to modify our model specification a bit:</p><pre><code class="language-julia hljs">@model function rx_identification(f)
    
    # We are going to continuosly update our priors
    # based on new posteriors
    m_x_0 = datavar(Float64) 
    τ_x_0 = datavar(Float64)
    m_w_0 = datavar(Float64) 
    τ_w_0 = datavar(Float64)
    a_x   = datavar(Float64) 
    b_x   = datavar(Float64)
    a_y   = datavar(Float64) 
    b_y   = datavar(Float64)
    a_w   =  datavar(Float64) 
    b_w   = datavar(Float64)
    s     = randomvar()
    y     = datavar(Float64)
    
    x0 ~ Normal(mean = m_x_0, precision = τ_x_0)
    τ_x ~ Gamma(shape = a_x, rate = b_x)
    w0 ~ Normal(mean = m_w_0, precision = τ_w_0)
    τ_w ~ Gamma(shape = a_w, rate = b_w)
    τ_y ~ Gamma(shape = a_y, rate = b_y)
    
    x ~ Normal(mean = x0, precision = τ_x)
    w ~ Normal(mean = w0, precision = τ_w)

    s ~ f(x, w)
    y ~ Normal(mean = s, precision = τ_y)
    
end</code></pre><p>We impose structured mean-field assumption for this model as well:</p><pre><code class="language-julia hljs">rx_constraints = @constraints begin 
    q(x0, x, w0, w, τ_x, τ_w, τ_y, s) = q(x0, x)q(w, w0)q(τ_w)q(τ_x)q(s)q(τ_y)
end</code></pre><pre><code class="nohighlight hljs">Constraints:
  marginals form:
  messages form:
  factorisation:
    q(x0, x, w0, w, τ_x, τ_w, τ_y, s) = q(x0, x)q(w, w0)q(τ_w)q(τ_x)q(s)q(τ
_y)
Options:
  warn = true</code></pre><p>Online inference in the <code>RxInfer</code> supports the <code>@autoupdates</code> specification, which tells inference procedure how to update priors based on new computed posteriors:</p><pre><code class="language-julia hljs">autoupdates = @autoupdates begin 
    m_x_0, τ_x_0 = mean_precision(q(x))
    m_w_0, τ_w_0 = mean_precision(q(w))
    a_x = shape(q(τ_x)) 
    b_x = rate(q(τ_x))
    a_y = shape(q(τ_y))
    b_y = rate(q(τ_y))
    a_w = shape(q(τ_w)) 
    b_w = rate(q(τ_w))
end</code></pre><pre><code class="nohighlight hljs">(m_x_0,τ_x_0 = mean_precision(q(x)), m_w_0,τ_w_0 = mean_precision(q(w)), a_
x = shape(q(τ_x)), b_x = rate(q(τ_x)), a_y = shape(q(τ_y)), b_y = rate(q(τ_
y)), a_w = shape(q(τ_w)), b_w = rate(q(τ_w)))</code></pre><p>As previously we need to define the <code>@meta</code> structure that specifies the approximation method for the nonlinear function <code>smooth_min</code> (<code>f</code> in the model specification):</p><pre><code class="language-julia hljs">rx_meta = @meta begin 
    smooth_min() -&gt; Linearization()
end</code></pre><pre><code class="nohighlight hljs">Meta specification:
  smooth_min() -&gt; Linearization()
Options:
  warn = true</code></pre><p>Next step is to generate our dataset and to run the actual inference procedure! For that we use the <code>rxinference</code> function, which has a similar API as the <code>inference</code> function:</p><pre><code class="language-julia hljs">n = 300
rx_real_x, rx_real_w, rx_real_y = generate_data(min, n, seed = 1, x_i_min = 1.0, w_i_min = -1.0, noise = 1.0, real_x_τ = 1.0, real_w_τ = 1.0);

pl = plot(title = &quot;Underlying signals&quot;)
pl = plot!(pl, rx_real_x, label = &quot;x&quot;)
pl = plot!(pl, rx_real_w, label = &quot;w&quot;)

pr = plot(title = &quot;Combined y = min(x, w)&quot;)
pr = scatter!(pr, rx_real_y, ms = 3, color = :red, label = &quot;y&quot;)

plot(pl, pr, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_19_1.png" alt/></p><pre><code class="language-julia hljs">engine = rxinference(
    model         = rx_identification(smooth_min),
    constraints   = rx_constraints,
    data          = (y = rx_real_y,),
    autoupdates   = autoupdates,
    meta          = rx_meta,
    returnvars    = (:x, :w, :τ_x, :τ_w, :τ_y, :s),
    keephistory   = 1000,
    historyvars   =  KeepLast(),
    initmarginals = (w = NormalMeanVariance(-2.0, 1.0), x = NormalMeanVariance(2.0, 1.0), τ_x = GammaShapeRate(1.0, 1.0), τ_w = GammaShapeRate(1.0, 1.0), τ_y = GammaShapeRate(1.0, 20.0)),
    iterations    = 10,
    free_energy = true, 
    free_energy_diagnostics = nothing,
    autostart     = true,
)</code></pre><pre><code class="nohighlight hljs">RxInferenceEngine:
  Posteriors stream    | enabled for (w, s, τ_x, τ_w, τ_y, x)
  Free Energy stream   | enabled
  Posteriors history   | available for (x, w, x0, s, τ_x, τ_w, τ_y, w0)
  Free Energy history  | available
  Enabled events       | [  ]</code></pre><pre><code class="language-julia hljs">rx_smarginals = engine.history[:s]
rx_xmarginals = engine.history[:x]
rx_wmarginals = engine.history[:w];</code></pre><pre><code class="language-julia hljs">px1 = plot(legend = :bottomleft, title = &quot;Estimated hidden signals&quot;)
px2 = plot(legend = :bottomright, title = &quot;Estimated combined signals&quot;)

px1 = plot!(px1, rx_real_x, label = &quot;Real hidden X&quot;)
px1 = plot!(px1, mean.(rx_xmarginals), ribbon = var.(rx_xmarginals), label = &quot;Estimated X&quot;)

px1 = plot!(px1, rx_real_w, label = &quot;Real hidden W&quot;)
px1 = plot!(px1, mean.(rx_wmarginals), ribbon = var.(rx_wmarginals), label = &quot;Estimated W&quot;)

px2 = scatter!(px2, rx_real_y, label = &quot;Observations&quot;, ms = 2, alpha = 0.5, color = :red)
px2 = plot!(px2, mean.(rx_smarginals), ribbon = std.(rx_smarginals), label = &quot;Combined estimated signal&quot;, color = :green)

plot(px1, px2, size = (800, 300))</code></pre><p><img src="../../assets/examples/Identification Problem_22_1.png" alt/></p><p>The results are quite similar to the smoothing case and, as we can see, one of the random walk is again in the &quot;disabled&quot; state, does not infer anything and simply increases its variance (which is expected for the random walk).</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Infinite Data Stream/">« Infinite Data Stream</a><a class="docs-footer-nextpage" href="../Gaussian Mixture Univariate/">Univariate Gaussian Mixture Model »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 13 February 2023 08:35">Monday 13 February 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
